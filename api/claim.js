// ê²½ë¡œ: api/claim.js

import fs from 'fs/promises';
import path from 'path';

export default async function handler(req, res) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method Not Allowed' });
  }

  // ğŸ”§ textë¡œ ë“¤ì–´ì˜¨ ê°’ì„ passageë¡œ ë§¤í•‘
  const { text: passage } = req.body;
  if (!passage || typeof passage !== 'string') {
    return res.status(400).json({ error: 'Invalid or missing passage' });
  }

  try {
    const p = passage;

    // 1. ì£¼ì¥ ë¬¸ì¥ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    const hasClaim = await fetchPrompt('clm2.txt', { p });
    let finalPassage = p;

    if (hasClaim.trim().toUpperCase() === 'NO') {
      const qraw = await fetchPrompt('clm5.txt', { p });
      finalPassage = qraw.trim();
    }

    // 2. ì„ íƒì§€ ìƒì„±
    const c = (await fetchPrompt('clm3-1.txt', { p: finalPassage }, 'gpt-4o')).trim();
    const w = (await fetchPrompt('clm3-2-w.txt', { p: finalPassage, c })).trim();
    const x = (await fetchPrompt('clm3-2-x.txt', { p: finalPassage, c, w })).trim();
    const y = (await fetchPrompt('clm3-3-y.txt', { p: finalPassage, c, w, x })).trim();
    const z = (await fetchPrompt('clm3-3-z.txt', { p: finalPassage, c, w, x, y })).trim();

    const options = [c, w, x, y, z];
    const sorted = [...options].sort((a, b) => a.length - b.length);
    const labels = ['â‘ ','â‘¡','â‘¢','â‘£','â‘¤'];
    const correctIndex = sorted.findIndex(opt => opt.trim() === c.trim());
    const optionItems = sorted.map((opt, i) => ({ label: labels[i], text: opt }));

    // 3. í•´ì„¤ ìƒì„±
    const e = (await fetchPrompt('clm3-5-e.txt', { p: finalPassage, c })).trim();
    const f = (await fetchPrompt('clm3-5-f.txt', { p: finalPassage, c })).trim();
    const answerNum = labels[correctIndex];
    const josa = ['ì´','ê°€','ì´','ê°€','ê°€'][correctIndex];
    const explanation = `${e} í•„ìì˜ ì£¼ì¥ì€, ë¬¸ì¥ ${f}ì—ì„œ ê°€ì¥ ëª…ì‹œì ìœ¼ë¡œ ë“œëŸ¬ë‚œë‹¤. ë”°ë¼ì„œ, ê¸€ì˜ ì£¼ì¥ìœ¼ë¡œëŠ” ${answerNum}${josa} ê°€ì¥ ì ì ˆí•˜ë‹¤.`;

    // 4. body ì¡°ë¦½
    const body = `
      <p>${finalPassage}</p>
      <ul>
        ${optionItems.map(item => `<li>${item.label} ${item.text}</li>`).join('')}
      </ul>
    `;

    res.status(200).json({
      prompt: 'ë‹¤ìŒ ê¸€ì—ì„œ í•„ìê°€ ì£¼ì¥í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì¥ ì ì ˆí•œ ê²ƒì€?',
      body,
      answer: answerNum,
      explanation
    });

  } catch (err) {
    console.error('clm API error:', err);
    res.status(500).json({ error: 'Failed to generate claim question' });
  }
}

async function fetchPrompt(file, replacements, model = 'gpt-3.5-turbo') {
  const filePath = path.join(process.cwd(), 'api', 'prompts', file);
  let prompt = await fs.readFile(filePath, 'utf-8');

  for (const key in replacements) {
    prompt = prompt.replace(new RegExp(`{{${key}}}`, 'g'), replacements[key]);
  }

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`
    },
    body: JSON.stringify({
      model,
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.3
    })
  });

  const data = await response.json();
  if (data.error) throw new Error(data.error.message || 'GPT ì‘ë‹µ ì‹¤íŒ¨');
  return data.choices[0].message.content.trim();
}
